标准的少样本提示技术在许多任务中表现良好，但仍然不是一项完美的技术，特别是在处理更加复杂的推理任务时。让我们给出一个示例加以说明（下述示例基于GPT-3模型测试）：

```latex
Prompt: 现有一个数列：15、32、5、13、82、7、1，请问其中的奇数之和是奇数吗
Output: 是奇数，奇数之和为127。
```

不难发现，这里的回复是错误的，上述例子展示了仅使用零样本提示的局限性，我们需要更先进的提示工程技术帮助模型做出正确的回答。让我们尝试添加一些示例，看看是否可以通过少样本提示来提高结果的准确性。

```latex
Prompt: 数列4, 8, 9, 15, 12, 2, 1中的奇数相加得到一个偶数 // 答案：错误
	数列17, 10, 19, 4, 8, 12, 24中的奇数相加得到一个偶数 // 答案：正确
	数列16, 11, 14, 4, 8, 13, 24中的奇数相加得到一个偶数 // 答案：正确
	数列17, 9, 10, 12, 13, 4, 2中的奇数相加得到一个偶数 // 答案：错误
	数列15, 32, 5, 13, 82, 7, 1中的奇数相加得到一个偶数 // 答案：
Output: 正确
```

可以看出，即使给出了少样本提示，结果仍然是不正确的，这证明了模型无法解决这类较为复杂的推理问题。因此，模型需要进行多步推理才能得到最终答案。一个直观的想法是：如果我们向模型展示求解问题的步骤，可能会提高模型的推理效果。近年来，思维链（CoT）提示已成为解决更复杂的算术、常识和符号推理任务的流行方案。

总的来说，提供示例对于解决某些任务是非常有用的。当零样本提示和少样本提示无法给出正确结果时，这可能意味着模型所学知识不足以在该任务上表现出色。因此，建议开始考虑微调模型或尝试更高级的提示技术。接下来我们将讨论一种叫做思维链提示的技术。
